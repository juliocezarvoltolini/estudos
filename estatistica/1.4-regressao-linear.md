# 1.4 â€” AnÃ¡lise de RegressÃ£o Linear

> ğŸ“¦ **MÃ³dulo 1 â€” Fundamentos MatemÃ¡ticos e EstatÃ­sticos**
> ğŸ¯ **NÃ­vel:** Iniciante | âœ… **Cobrado em concurso:** Frequentemente

---

## ğŸ¤” Por que estudar RegressÃ£o Linear?

VocÃª quer prever o tempo que um processo judicial vai durar com base no nÃºmero de rÃ©us. Ou prever o salÃ¡rio de um servidor com base nos anos de serviÃ§o. Ou prever o consumo de energia de um servidor com base na quantidade de requisiÃ§Ãµes.

Em todos esses casos, vocÃª tem **uma variÃ¡vel que quer prever (Y)** e **uma ou mais variÃ¡veis que explicam Y (X)**. A **RegressÃ£o Linear** Ã© a ferramenta para modelar e quantificar essa relaÃ§Ã£o.

> ğŸ“Œ A regressÃ£o linear Ã© o algoritmo de Machine Learning mais fundamental. EntendÃª-la bem Ã© essencial para compreender desde os modelos mais simples atÃ© redes neurais profundas.

---

## ğŸ“ PARTE 1 â€” RegressÃ£o Linear Simples

### Conceito

A regressÃ£o linear simples modela a relaÃ§Ã£o entre **uma variÃ¡vel preditora (X)** e **uma variÃ¡vel resposta (Y)** por meio de uma **linha reta**.

```
         Y
         |          /
         |        /  â† linha de regressÃ£o
         |      / Â·
         |    Â· /
         |  /  Â·  Â·
         |/ Â·
         Â·â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ X
```

Os pontos (Â·) sÃ£o os dados reais. A linha Ã© o melhor ajuste linear a esses pontos.

---

### O Modelo

```
Y = Î²â‚€ + Î²â‚ Ã— X + Îµ
```

**Lendo a equaÃ§Ã£o:**

| SÃ­mbolo | Nome | Significado |
|---------|------|-------------|
| **Y** | VariÃ¡vel dependente | O que queremos prever (resposta) |
| **X** | VariÃ¡vel independente | O que usamos para prever (preditor) |
| **Î²â‚€** (beta zero) | Intercepto | Valor de Y quando X = 0 (ponto onde a reta cruza o eixo Y) |
| **Î²â‚** (beta um) | Coeficiente angular | Quanto Y muda para cada 1 unidade a mais em X |
| **Îµ** (Ã©psilon) | Erro/ResÃ­duo | Parte de Y que o modelo nÃ£o consegue explicar |

---

**ğŸ“Œ Exemplo 1 â€” SalÃ¡rio por anos de experiÃªncia:**

Modelo ajustado: **Å¶ = 2.500 + 500 Ã— X**
- Î²â‚€ = 2.500 â†’ salÃ¡rio base (sem experiÃªncia) = R$ 2.500
- Î²â‚ = 500 â†’ cada ano a mais de experiÃªncia acrescenta R$ 500 ao salÃ¡rio

PrevisÃµes:
```
X = 3 anos: Å¶ = 2.500 + 500 Ã— 3 = R$ 4.000
X = 8 anos: Å¶ = 2.500 + 500 Ã— 8 = R$ 6.500
X = 0 anos: Å¶ = 2.500 + 500 Ã— 0 = R$ 2.500 (intercepto)
```

> ğŸ’¡ **Importante:** O sÃ­mbolo Å¶ (Y-chapÃ©u) Ã© o **valor previsto** pelo modelo. O valor real Ã© Y. A diferenÃ§a Y âˆ’ Å¶ Ã© o **resÃ­duo (Îµ)**.

---

**ğŸ“Œ Exemplo 2 â€” Temperatura e consumo de energia:**

Modelo: **Å¶ = 100 + 3,5 Ã— X**
- X = temperatura (Â°C), Y = consumo de energia (kWh)
- Î²â‚€ = 100 â†’ consumo base de 100 kWh a 0Â°C
- Î²â‚ = 3,5 â†’ cada grau a mais aumenta 3,5 kWh no consumo

PrevisÃ£o para 30Â°C: Å¶ = 100 + 3,5 Ã— 30 = **205 kWh**

---

### MÃ©todo dos MÃ­nimos Quadrados OrdinÃ¡rios (MQO)

Como encontramos a "melhor" reta? O MQO minimiza a **Soma dos Quadrados dos ResÃ­duos (SSE)**:

```
SSE = Î£(Yáµ¢ âˆ’ Å¶áµ¢)Â² = Î£(Yáµ¢ âˆ’ Î²â‚€ âˆ’ Î²â‚Xáµ¢)Â²
```

**Lendo a fÃ³rmula:**
- Para cada observaÃ§Ã£o i, calculamos o resÃ­duo (Yáµ¢ âˆ’ Å¶áµ¢)
- Elevamos ao quadrado (para eliminar negativos e penalizar erros grandes)
- Somamos todos
- A reta que minimiza esse total Ã© a melhor reta

**Por que elevar ao quadrado?** Sem isso, resÃ­duos positivos e negativos se cancelariam e qualquer reta com mÃ©dia zero de resÃ­duos pareceria boa.

**FÃ³rmulas dos coeficientes:**

```
Î²â‚ = Î£[(Xáµ¢ âˆ’ XÌ„)(Yáµ¢ âˆ’ È²)] / Î£[(Xáµ¢ âˆ’ XÌ„)Â²]    (covariÃ¢ncia / variÃ¢ncia de X)

Î²â‚€ = È² âˆ’ Î²â‚ Ã— XÌ„
```

**Lendo:**
- XÌ„ = mÃ©dia de X
- È² = mÃ©dia de Y
- A reta de regressÃ£o sempre passa pelo ponto (XÌ„, È²)

---

**ğŸ“Œ Exemplo de cÃ¡lculo:**

Dados: horas de estudo (X) e nota (Y)

| i | X | Y | Xáµ¢ âˆ’ XÌ„ | Yáµ¢ âˆ’ È² | (Xáµ¢âˆ’XÌ„)Â² | (Xáµ¢âˆ’XÌ„)(Yáµ¢âˆ’È²) |
|---|---|---|---------|---------|----------|--------------|
| 1 | 2 | 5 | âˆ’2 | âˆ’2,5 | 4 | 5 |
| 2 | 4 | 7 | 0 | âˆ’0,5 | 0 | 0 |
| 3 | 5 | 8 | 1 | 0,5 | 1 | 0,5 |
| 4 | 7 | 10 | 3 | 2,5 | 9 | 7,5 |
| **Î£** | **18** | **30** | 0 | 0 | 14 | 13 |

```
XÌ„ = 18/4 = 4,5     È² = 30/4 = 7,5

Î²â‚ = 13 / 14 â‰ˆ 0,929

Î²â‚€ = 7,5 âˆ’ 0,929 Ã— 4,5 â‰ˆ 7,5 âˆ’ 4,18 â‰ˆ 3,32
```

**Modelo:** Å¶ = 3,32 + 0,929 Ã— X

InterpretaÃ§Ã£o: cada hora a mais de estudo aumenta a nota em aproximadamente **0,93 pontos**.

---

## ğŸ“Š PARTE 2 â€” RegressÃ£o Linear MÃºltipla

### Conceito

Quando a variÃ¡vel resposta Y depende de **mais de um preditor**, usamos a regressÃ£o mÃºltipla:

```
Y = Î²â‚€ + Î²â‚Xâ‚ + Î²â‚‚Xâ‚‚ + ... + Î²â‚–Xâ‚– + Îµ
```

**ğŸ“Œ Exemplo:**
Prever o preÃ§o de um apartamento (Y) com base em:
- Xâ‚ = Ã¡rea (mÂ²)
- Xâ‚‚ = nÃºmero de quartos
- Xâ‚ƒ = distÃ¢ncia do centro (km)

Modelo ajustado:
```
Å¶ = 50.000 + 3.500Ã—Xâ‚ + 15.000Ã—Xâ‚‚ âˆ’ 8.000Ã—Xâ‚ƒ
```

InterpretaÃ§Ã£o dos coeficientes:
- Î²â‚ = 3.500 â†’ cada mÂ² a mais acrescenta R$ 3.500 (mantendo quartos e distÃ¢ncia fixos)
- Î²â‚‚ = 15.000 â†’ cada quarto a mais acrescenta R$ 15.000 (mantendo mÂ² e distÃ¢ncia fixos)
- Î²â‚ƒ = âˆ’8.000 â†’ cada km a mais do centro reduz R$ 8.000 (mantendo mÂ² e quartos fixos)

> ğŸ’¡ Cada coeficiente representa o **efeito isolado** daquela variÃ¡vel, mantendo as demais constantes. Isso Ã© chamado de **efeito parcial**.

---

### Problemas Comuns na RegressÃ£o MÃºltipla

#### 1. Multicolinearidade

Ocorre quando dois ou mais **preditores estÃ£o altamente correlacionados entre si**.

**Problema:** o modelo nÃ£o consegue separar o efeito de cada um. Os coeficientes ficam instÃ¡veis e podem ter sinais errados.

**Exemplo:** incluir no modelo tanto "Ã¡rea em mÂ²" quanto "Ã¡rea em ftÂ²" â€” elas sÃ£o praticamente a mesma coisa (sÃ³ uma Ã© conversÃ£o da outra).

**DiagnÃ³stico:** VIF (Variance Inflation Factor)
- VIF < 5: aceitÃ¡vel
- VIF entre 5 e 10: preocupante
- VIF > 10: multicolinearidade severa â†’ remover um dos preditores

#### 2. Heterocedasticidade

Ocorre quando a **variÃ¢ncia dos resÃ­duos nÃ£o Ã© constante** â€” ela muda conforme os valores de X.

**VisualizaÃ§Ã£o:** no grÃ¡fico de resÃ­duos, vocÃª vÃª um "cone" â€” os erros ficam maiores conforme X aumenta.

**ConsequÃªncia:** os testes de hipÃ³tese ficam invÃ¡lidos (intervalos de confianÃ§a incorretos).

#### 3. Overfitting (Sobreajuste)

Adicionar muitos preditores pode fazer o modelo se ajustar **demais** aos dados de treino, perdendo capacidade de generalizar para dados novos.

> ğŸ† **Dica de concurso:** Multicolinearidade Ã© o problema mais cobrado na regressÃ£o mÃºltipla. Lembre: VIF > 10 = problema sÃ©rio.

---

## ğŸ” PARTE 3 â€” AnÃ¡lise de ResÃ­duos e AvaliaÃ§Ã£o do Modelo

### O ResÃ­duo

```
ResÃ­duo (eáµ¢) = Yáµ¢ âˆ’ Å¶áµ¢   (valor real âˆ’ valor previsto)
```

Os resÃ­duos dizem o quanto o modelo errou em cada previsÃ£o. A anÃ¡lise dos resÃ­duos verifica se o modelo estÃ¡ bem especificado.

---

### SuposiÃ§Ãµes da RegressÃ£o Linear â€” MnemÃ´nico: **LINE**

| Letra | SuposiÃ§Ã£o | Como verificar |
|-------|-----------|----------------|
| **L** | **L**inearidade: relaÃ§Ã£o entre X e Y Ã© linear | GrÃ¡fico de dispersÃ£o; grÃ¡fico resÃ­duos vs X |
| **I** | **I**ndependÃªncia dos erros: resÃ­duos nÃ£o sÃ£o correlacionados | GrÃ¡fico de resÃ­duos ao longo do tempo; Teste de Durbin-Watson |
| **N** | **N**ormalidade dos erros: resÃ­duos seguem dist. normal | Histograma dos resÃ­duos; grÃ¡fico Q-Q |
| **E** | **E**rros com variÃ¢ncia constante (homocedasticidade) | GrÃ¡fico resÃ­duos vs valores ajustados |

> ğŸ† **Dica de concurso:** O acrÃ´nimo LINE Ã© cobrado em concursos como resumo das premissas da regressÃ£o.

---

### MÃ©tricas de AvaliaÃ§Ã£o

#### Coeficiente de DeterminaÃ§Ã£o (RÂ²)

Indica qual **proporÃ§Ã£o da variaÃ§Ã£o de Y** Ã© explicada pelo modelo:

```
RÂ² = SSR / SST = 1 âˆ’ (SSE / SST)
```

**Onde:**
- **SST** (Total Sum of Squares) = variaÃ§Ã£o total de Y em torno de È²
  - SST = Î£(Yáµ¢ âˆ’ È²)Â²
- **SSR** (Regression Sum of Squares) = variaÃ§Ã£o explicada pelo modelo
  - SSR = Î£(Å¶áµ¢ âˆ’ È²)Â²
- **SSE** (Error Sum of Squares) = variaÃ§Ã£o nÃ£o explicada (resÃ­duos)
  - SSE = Î£(Yáµ¢ âˆ’ Å¶áµ¢)Â²
- RelaÃ§Ã£o: **SST = SSR + SSE**

**InterpretaÃ§Ã£o do RÂ²:**

| RÂ² | InterpretaÃ§Ã£o |
|----|---------------|
| 0 | Modelo nÃ£o explica nada da variaÃ§Ã£o de Y |
| 0,75 | Modelo explica 75% da variaÃ§Ã£o de Y |
| 1 | Modelo explica 100% (ajuste perfeito â€” suspeito!) |

---

**ğŸ“Œ Exemplo:**
Um modelo de previsÃ£o de notas tem RÂ² = 0,82.
â†’ 82% da variaÃ§Ã£o nas notas Ã© explicada pelas horas de estudo.
â†’ 18% Ã© explicada por outros fatores nÃ£o incluÃ­dos no modelo.

---

#### âš ï¸ RÂ² vs RÂ² Ajustado

Problema do RÂ²: ele **sempre aumenta** quando adicionamos novas variÃ¡veis, mesmo que sejam irrelevantes!

O **RÂ² Ajustado** penaliza a inclusÃ£o de variÃ¡veis irrelevantes:

```
RÂ²_ajustado = 1 âˆ’ [(1 âˆ’ RÂ²) Ã— (n âˆ’ 1) / (n âˆ’ k âˆ’ 1)]
```

- **n** = nÃºmero de observaÃ§Ãµes
- **k** = nÃºmero de preditores

Se o RÂ² ajustado cair ao incluir uma nova variÃ¡vel â†’ a variÃ¡vel nÃ£o agrega ao modelo.

> ğŸ† **Dica de concurso:** Na comparaÃ§Ã£o de modelos com diferentes nÃºmeros de variÃ¡veis, sempre use o **RÂ² ajustado**, nunca o RÂ² simples.

---

### Tabela de DecomposiÃ§Ã£o da VariÃ¢ncia (ANOVA da RegressÃ£o)

| Fonte | Soma de Quadrados | Graus de Liberdade | MÃ©dia QuadrÃ¡tica |
|-------|------------------|--------------------|-----------------|
| **RegressÃ£o** | SSR | k | SSR/k |
| **ResÃ­duo (Erro)** | SSE | n âˆ’ k âˆ’ 1 | SSE/(nâˆ’kâˆ’1) |
| **Total** | SST | n âˆ’ 1 | â€” |

O **Teste F** usa essa tabela para verificar se o modelo como um todo Ã© significativo:

```
Hâ‚€: Î²â‚ = Î²â‚‚ = ... = Î²â‚– = 0 (modelo sem utilidade)
Hâ‚: pelo menos um Î²áµ¢ â‰  0 (modelo tem utilidade)
```

Se p-valor do teste F < Î± â†’ modelo Ã© estatisticamente significativo.

---

## âœ… Resumo â€” O que mais cai em concurso

| TÃ³pico | Ponto CrÃ­tico |
|--------|---------------|
| **Intercepto (Î²â‚€)** | Valor de Y quando X = 0 |
| **Coeficiente angular (Î²â‚)** | VariaÃ§Ã£o em Y para +1 unidade em X |
| **MQO** | Minimiza a **soma dos quadrados** dos resÃ­duos |
| **RÂ²** | ProporÃ§Ã£o da variaÃ§Ã£o de Y explicada pelo modelo (0 a 1) |
| **RÂ² ajustado** | Penaliza variÃ¡veis irrelevantes â€” use para comparar modelos |
| **SST = SSR + SSE** | DecomposiÃ§Ã£o da variaÃ§Ã£o total |
| **SuposiÃ§Ãµes LINE** | Linearidade, IndependÃªncia, Normalidade, Erros homocedÃ¡sticos |
| **Multicolinearidade** | Preditores correlacionados; VIF > 10 = severo |
| **ResÃ­duo** | eáµ¢ = Yáµ¢ âˆ’ Å¶áµ¢ (real âˆ’ previsto) |
| **Å¶ (Y-chapÃ©u)** | Valor **previsto** pelo modelo |

---

## ğŸ”— ConexÃ£o com o prÃ³ximo tÃ³pico (1.5 â€” TÃ©cnicas de Amostragem)

Aprendemos a construir e avaliar modelos de regressÃ£o. Mas a qualidade de um modelo depende diretamente da **qualidade e representatividade dos dados** usados para treinÃ¡-lo.

Se a amostra for viciada (por exemplo, sÃ³ incluir servidores de uma regiÃ£o), o modelo vai funcionar bem apenas para aquela regiÃ£o. As **TÃ©cnicas de Amostragem** garantem que os dados coletados representem adequadamente a populaÃ§Ã£o de interesse.

AlÃ©m disso, no MÃ³dulo 5, a regressÃ£o linear reaparecerÃ¡ como tÃ©cnica de Machine Learning supervisionada, com mÃ©tricas de avaliaÃ§Ã£o especÃ­ficas como MAE, MSE e RMSE.

---

*ğŸ“… PrÃ³ximo tÃ³pico: **1.5 â€” TÃ©cnicas de Amostragem***
