# 1.2 â€” Probabilidade e DistribuiÃ§Ãµes

> ğŸ“¦ **MÃ³dulo 1 â€” Fundamentos MatemÃ¡ticos e EstatÃ­sticos**
> ğŸ¯ **NÃ­vel:** Iniciante | âœ… **Cobrado em concurso:** Muito frequentemente

---

## ğŸ¤” Por que estudar probabilidade?

Todo modelo de Machine Learning lida com **incerteza**. Quando um algoritmo diz "hÃ¡ 87% de chance de este e-mail ser spam", estÃ¡ usando probabilidade. Quando um modelo prevÃª o risco de inadimplÃªncia de um cliente, estÃ¡ usando probabilidade.

A probabilidade Ã© a **linguagem matemÃ¡tica da incerteza**. Ela quantifica o quÃ£o provÃ¡vel Ã© que algo aconteÃ§a.

---

## ğŸ² PARTE 1 â€” Conceitos BÃ¡sicos de Probabilidade

### O que Ã© Probabilidade?

Probabilidade Ã© um nÃºmero entre **0 e 1** que expressa a chance de um evento ocorrer:

```
P(A) = 0     â†’ o evento A Ã© impossÃ­vel
P(A) = 1     â†’ o evento A Ã© certo
0 < P(A) < 1 â†’ o evento A Ã© possÃ­vel
```

**DefiniÃ§Ã£o clÃ¡ssica (experimentos com resultados igualmente provÃ¡veis):**

```
P(A) = (nÃºmero de resultados favorÃ¡veis a A) / (nÃºmero total de resultados possÃ­veis)
```

**ğŸ“Œ Exemplo 1 â€” Dado:**
Ao lanÃ§ar um dado de 6 faces, qual a probabilidade de sair nÃºmero par?
- Resultados possÃ­veis: {1, 2, 3, 4, 5, 6} â†’ 6 resultados
- Resultados favorÃ¡veis (par): {2, 4, 6} â†’ 3 resultados
```
P(par) = 3/6 = 0,5 = 50%
```

**ğŸ“Œ Exemplo 2 â€” Baralho:**
Ao tirar uma carta de um baralho comum (52 cartas), qual a probabilidade de ser um Ãs?
- Resultados possÃ­veis: 52 cartas
- Resultados favorÃ¡veis (Ãs): 4 cartas (um de cada naipe)
```
P(Ãs) = 4/52 = 1/13 â‰ˆ 0,077 â‰ˆ 7,7%
```

---

### Conceitos Fundamentais

| Termo | DefiniÃ§Ã£o | Exemplo |
|-------|-----------|---------|
| **Experimento aleatÃ³rio** | Experimento cujo resultado nÃ£o Ã© previsÃ­vel com certeza | LanÃ§ar uma moeda |
| **EspaÃ§o amostral (Î©)** | Conjunto de todos os resultados possÃ­veis | {Cara, Coroa} |
| **Evento** | Subconjunto do espaÃ§o amostral | "Sair cara" |
| **Evento complementar (Aá¶œ)** | Tudo que nÃ£o Ã© A | P(Aá¶œ) = 1 âˆ’ P(A) |

**ğŸ“Œ Exemplo com complementar:**
P(chover amanhÃ£) = 0,30 â†’ P(nÃ£o chover) = 1 âˆ’ 0,30 = **0,70**

---

## ğŸ”— PARTE 2 â€” Probabilidade Condicional e IndependÃªncia

### Probabilidade Condicional

A probabilidade condicional responde: **"Se eu jÃ¡ sei que B ocorreu, qual a probabilidade de A ocorrer?"**

```
P(A|B) = P(A âˆ© B) / P(B)
```

**Lendo a fÃ³rmula:**
- **P(A|B)** = "probabilidade de A **dado** B" (lÃª-se: "P de A dado B")
- **P(A âˆ© B)** = probabilidade de A **e** B ocorrerem juntos (interseÃ§Ã£o)
- **P(B)** = probabilidade de B ocorrer (B deve ter probabilidade > 0)

---

**ğŸ“Œ Exemplo 1 â€” Dados de saÃºde:**

Em uma pesquisa, sabe-se que:
- 30% da populaÃ§Ã£o Ã© fumante: P(F) = 0,30
- 12% da populaÃ§Ã£o Ã© fumante **e** tem problemas respiratÃ³rios: P(F âˆ© R) = 0,12

Qual a probabilidade de ter problema respiratÃ³rio, **dado que** Ã© fumante?

```
P(R|F) = P(R âˆ© F) / P(F)
P(R|F) = 0,12 / 0,30
P(R|F) = 0,40 = 40%
```
Entre os fumantes, 40% tÃªm problemas respiratÃ³rios.

---

**ğŸ“Œ Exemplo 2 â€” Dados de concurso:**

Em um processo seletivo:
- 60% dos candidatos estudaram para a prova: P(E) = 0,60
- 48% dos candidatos estudaram **e** foram aprovados: P(E âˆ© A) = 0,48

Qual a probabilidade de aprovaÃ§Ã£o entre os que estudaram?

```
P(A|E) = P(A âˆ© E) / P(E)
P(A|E) = 0,48 / 0,60
P(A|E) = 0,80 = 80%
```
Quem estudou tem 80% de chance de aprovaÃ§Ã£o!

---

### Teorema de Bayes

O Teorema de Bayes permite **inverter** a probabilidade condicional. Ã‰ um dos resultados mais importantes da estatÃ­stica.

```
P(A|B) = [P(B|A) Ã— P(A)] / P(B)
```

**Lendo a fÃ³rmula:**
- **P(A)** = probabilidade **a priori** (antes de observar B) â€” o que sabÃ­amos antes
- **P(B|A)** = probabilidade de observar B, **sabendo que A Ã© verdadeiro** (verossimilhanÃ§a)
- **P(A|B)** = probabilidade **a posteriori** (apÃ³s observar B) â€” o que aprendemos

> ğŸ’¡ IntuiÃ§Ã£o: Bayes nos diz como **atualizar nossa crenÃ§a** sobre A quando aprendemos que B aconteceu.

---

**ğŸ“Œ Exemplo â€” Teste de diagnÃ³stico mÃ©dico:**

Uma doenÃ§a afeta 1% da populaÃ§Ã£o: P(D) = 0,01
O teste tem as seguintes caracterÃ­sticas:
- Se a pessoa tem a doenÃ§a, o teste dÃ¡ positivo em 95% dos casos: P(+|D) = 0,95
- Se a pessoa **nÃ£o tem** a doenÃ§a, o teste dÃ¡ positivo em 5% dos casos (falso positivo): P(+|Dá¶œ) = 0,05

**Pergunta:** Uma pessoa testou positivo. Qual a probabilidade de **realmente ter a doenÃ§a**?

IntuiÃ§Ã£o: como a doenÃ§a Ã© rara (1%), a maioria dos positivos Ã© falso positivo!

**Calculando P(B) = P(+):**
```
P(+) = P(+|D) Ã— P(D) + P(+|Dá¶œ) Ã— P(Dá¶œ)
P(+) = 0,95 Ã— 0,01 + 0,05 Ã— 0,99
P(+) = 0,0095 + 0,0495
P(+) = 0,059
```

**Aplicando Bayes:**
```
P(D|+) = [P(+|D) Ã— P(D)] / P(+)
P(D|+) = [0,95 Ã— 0,01] / 0,059
P(D|+) = 0,0095 / 0,059
P(D|+) â‰ˆ 0,161 = 16,1%
```

Surpreendente! Mesmo com um teste positivo, a probabilidade de ter a doenÃ§a Ã© de apenas ~16%! Isso porque a doenÃ§a Ã© muito rara.

> ğŸ† **Dica de concurso:** Bayes Ã© o fundamento do classificador **Naive Bayes** (MÃ³dulo 5). Ã‰ muito cobrado tanto o cÃ¡lculo quanto a interpretaÃ§Ã£o.

---

### IndependÃªncia de Eventos

Dois eventos sÃ£o **independentes** quando a ocorrÃªncia de um **nÃ£o afeta** a probabilidade do outro.

**Teste de independÃªncia:**
```
Se P(A âˆ© B) = P(A) Ã— P(B), entÃ£o A e B sÃ£o INDEPENDENTES
```

Equivalentemente: A e B sÃ£o independentes se P(A|B) = P(A) â€” saber que B ocorreu nÃ£o muda a probabilidade de A.

---

**ğŸ“Œ Exemplo 1 â€” Independentes:**
LanÃ§ar uma moeda duas vezes. O resultado do 1Âº lanÃ§amento afeta o 2Âº?
- P(cara no 1Âº) = 0,5
- P(cara no 2Âº) = 0,5
- P(cara nos dois) = 0,5 Ã— 0,5 = 0,25 âœ… SÃ£o independentes.

**ğŸ“Œ Exemplo 2 â€” Dependentes:**
Tirar duas cartas de um baralho **sem reposiÃ§Ã£o**.
- P(Ãs na 1Âª carta) = 4/52
- P(Ãs na 2Âª carta | Ãs na 1Âª) = 3/51 â† mudou! SÃ£o **dependentes**.

---

## ğŸ° PARTE 3 â€” VariÃ¡veis AleatÃ³rias

### O que Ã© uma VariÃ¡vel AleatÃ³ria?

Uma variÃ¡vel aleatÃ³ria (VA) Ã© uma **funÃ§Ã£o que associa um nÃºmero a cada resultado possÃ­vel** de um experimento aleatÃ³rio.

Em outras palavras: ela transforma um resultado qualitativo em um nÃºmero.

**ğŸ“Œ Exemplo:**
Experimento: lanÃ§ar uma moeda duas vezes
VariÃ¡vel aleatÃ³ria X = "nÃºmero de caras"

| Resultado | X |
|-----------|---|
| (Coroa, Coroa) | 0 |
| (Cara, Coroa) | 1 |
| (Coroa, Cara) | 1 |
| (Cara, Cara) | 2 |

---

### VariÃ¡veis Discretas vs ContÃ­nuas

| CaracterÃ­stica | **Discreta** | **ContÃ­nua** |
|---------------|--------------|--------------|
| **Valores** | ContÃ¡veis (inteiros) | Qualquer valor em um intervalo |
| **Exemplo** | NÂº de filhos, nÂº de defeitos | Altura, peso, temperatura, tempo |
| **RepresentaÃ§Ã£o** | Tabela de probabilidades | FunÃ§Ã£o de densidade (curva) |
| **Probabilidade de um ponto** | P(X = k) pode ser > 0 | P(X = exato) = 0 |

**ğŸ“Œ Exemplos de VA Discreta:**
- NÃºmero de clientes que chegam a uma agÃªncia por hora
- NÃºmero de erros em um software
- Resultado de um dado

**ğŸ“Œ Exemplos de VA ContÃ­nua:**
- Tempo de espera em uma fila
- Temperatura de um servidor
- Peso de um pacote entregue

> ğŸ’¡ **Detalhe importante:** Para VA contÃ­nua, nÃ£o faz sentido perguntar P(X = 1,73m) â€” a probabilidade de qualquer valor **exato** Ã© zero. Perguntamos P(1,70 < X < 1,80).

---

### Valor Esperado (EsperanÃ§a)

O valor esperado E(X) Ã© a **mÃ©dia teÃ³rica** da variÃ¡vel aleatÃ³ria â€” o valor que esperarÃ­amos obter em mÃ©dia apÃ³s muitas repetiÃ§Ãµes do experimento.

**Para VA Discreta:**
```
E(X) = Î£ [xáµ¢ Ã— P(X = xáµ¢)]
```
Ou seja: multiplique cada valor pela sua probabilidade e some tudo.

**ğŸ“Œ Exemplo â€” Jogo de dados:**
Jogo: ganhe R$ 10 se sair 6, pague R$ 2 nos outros casos.

| Resultado | X (ganho) | P(X) |
|-----------|-----------|------|
| Sair 6 | + R$ 10 | 1/6 |
| NÃ£o sair 6 | âˆ’ R$ 2 | 5/6 |

```
E(X) = 10 Ã— (1/6) + (âˆ’2) Ã— (5/6)
E(X) = 10/6 âˆ’ 10/6
E(X) = 0
```
O valor esperado Ã© **zero** â€” o jogo Ã© "justo" (nem favorÃ¡vel nem desfavorÃ¡vel a longo prazo).

---

## ğŸ“Š PARTE 4 â€” DistribuiÃ§Ã£o Binomial

### Quando usar?

Use a distribuiÃ§Ã£o binomial quando o experimento tiver estas caracterÃ­sticas:

1. âœ… **n tentativas fixas** (nÃºmero determinado de repetiÃ§Ãµes)
2. âœ… **Cada tentativa tem apenas dois resultados** possÃ­veis: "sucesso" ou "fracasso"
3. âœ… **As tentativas sÃ£o independentes** entre si
4. âœ… **A probabilidade de sucesso (p) Ã© constante** em cada tentativa

**NotaÃ§Ã£o:** X ~ B(n, p) â†’ "X segue distribuiÃ§Ã£o Binomial com n tentativas e probabilidade de sucesso p"

---

### FÃ³rmula

```
P(X = k) = C(n,k) Ã— páµ Ã— (1âˆ’p)â¿â»áµ
```

**Lendo a fÃ³rmula:**
- **P(X = k)** = probabilidade de obter exatamente k sucessos
- **n** = nÃºmero de tentativas
- **k** = nÃºmero de sucessos desejados (k pode ser 0, 1, 2, ..., n)
- **p** = probabilidade de sucesso em cada tentativa
- **(1âˆ’p)** = probabilidade de fracasso (tambÃ©m chamada de q)
- **C(n,k)** = combinaÃ§Ã£o de n elementos tomados k a k = n! / [k! Ã— (nâˆ’k)!]

> ğŸ’¡ **O que Ã© C(n,k)?** Ã‰ o nÃºmero de maneiras de escolher k sucessos entre n tentativas, independente da ordem. Exemplo: C(5,2) = 10 maneiras de ter 2 sucessos em 5 tentativas.

---

**ParÃ¢metros da Binomial:**
```
MÃ©dia:    Î¼ = n Ã— p
VariÃ¢ncia: ÏƒÂ² = n Ã— p Ã— (1âˆ’p)
Desvio PadrÃ£o: Ïƒ = âˆš[n Ã— p Ã— (1âˆ’p)]
```

---

**ğŸ“Œ Exemplo 1 â€” LanÃ§amento de moeda:**
LanÃ§a-se uma moeda honesta 5 vezes. Qual a probabilidade de obter **exatamente 3 caras**?

- n = 5 (tentativas)
- k = 3 (sucessos desejados)
- p = 0,5 (probabilidade de cara)

```
C(5,3) = 5! / [3! Ã— 2!] = (5Ã—4Ã—3Ã—2Ã—1) / [(3Ã—2Ã—1) Ã— (2Ã—1)] = 120/12 = 10

P(X=3) = 10 Ã— (0,5)Â³ Ã— (0,5)Â²
P(X=3) = 10 Ã— 0,125 Ã— 0,25
P(X=3) = 10 Ã— 0,03125
P(X=3) = 0,3125 = 31,25%
```

---

**ğŸ“Œ Exemplo 2 â€” Controle de qualidade:**
Uma linha de produÃ§Ã£o tem 10% de probabilidade de produzir peÃ§as defeituosas. Em um lote de 20 peÃ§as, qual a probabilidade de **nenhuma peÃ§a** ser defeituosa?

- n = 20, k = 0, p = 0,10

```
C(20,0) = 1 (hÃ¡ apenas 1 maneira de ter 0 defeitos)

P(X=0) = 1 Ã— (0,10)â° Ã— (0,90)Â²â°
P(X=0) = 1 Ã— 1 Ã— (0,90)Â²â°
P(X=0) = 0,90Â²â° â‰ˆ 0,1216 â‰ˆ 12,2%
```
Apenas 12,2% de chance de um lote de 20 peÃ§as nÃ£o ter nenhum defeito.

MÃ©dia de defeitos por lote: Î¼ = 20 Ã— 0,10 = **2 peÃ§as**

> ğŸ† **Dica de concurso:** Identifique quando a situaÃ§Ã£o Ã‰ binomial: tentativas independentes, dois resultados, probabilidade constante. Isso cai mais do que o cÃ¡lculo em si.

---

## ğŸ“ˆ PARTE 5 â€” DistribuiÃ§Ã£o Normal (Gaussiana)

### O que Ã©?

A distribuiÃ§Ã£o Normal Ã© a mais importante de toda a estatÃ­stica. Ela descreve o comportamento de **inÃºmeros fenÃ´menos naturais**: altura de pessoas, erros de mediÃ§Ã£o, notas de exames, etc.

Seu grÃ¡fico tem formato de **sino simÃ©trico**:

```
           .oOOOo.
         oOO     OOo
        OO         OO
       OO           OO
------OO-------------OO------
      Î¼-2Ïƒ   Î¼   Î¼+2Ïƒ
```

**NotaÃ§Ã£o:** X ~ N(Î¼, ÏƒÂ²) â†’ "X segue distribuiÃ§Ã£o Normal com mÃ©dia Î¼ e variÃ¢ncia ÏƒÂ²"

---

### CaracterÃ­sticas Fundamentais

- âœ… **SimÃ©trica** em torno da mÃ©dia Î¼
- âœ… **MÃ©dia = Mediana = Moda** (todas iguais e no centro)
- âœ… **Assimetria = 0** e **Curtose = 0** (mesocÃºrtica)
- âœ… Completamente definida por apenas dois parÃ¢metros: Î¼ e Ïƒ
- âœ… A curva se aproxima do eixo X mas nunca o toca (assÃ­ntota)
- âœ… A Ã¡rea total sob a curva = 1 (100%)

---

### Regra EmpÃ­rica (68-95-99,7)

Esta Ã© **a regra mais cobrada em concurso** sobre a distribuiÃ§Ã£o normal:

```
Î¼ Â± 1Ïƒ  â†’ abrange aproximadamente 68% dos dados
Î¼ Â± 2Ïƒ  â†’ abrange aproximadamente 95% dos dados
Î¼ Â± 3Ïƒ  â†’ abrange aproximadamente 99,7% dos dados
```

**Visualizando:**
```
     |â†   68%   â†’|
     |â†      95%      â†’|
     |â†         99,7%         â†’|
â”€â”€â”€â”€â”€|â”€â”€â”€â”€|â”€â”€â”€â”€|â”€â”€â”€â”€|â”€â”€â”€â”€|â”€â”€â”€â”€|â”€â”€â”€â”€â”€
   Î¼-3Ïƒ  Î¼-2Ïƒ  Î¼-Ïƒ  Î¼   Î¼+Ïƒ  Î¼+2Ïƒ  Î¼+3Ïƒ
```

**ğŸ“Œ Exemplo:**
Altura de adultos brasileiros segue uma distribuiÃ§Ã£o Normal com:
- MÃ©dia (Î¼) = 170 cm
- Desvio PadrÃ£o (Ïƒ) = 10 cm

Aplicando a regra:
- Entre 160 e 180 cm (Î¼ Â± 1Ïƒ): **â‰ˆ 68%** das pessoas
- Entre 150 e 190 cm (Î¼ Â± 2Ïƒ): **â‰ˆ 95%** das pessoas
- Entre 140 e 200 cm (Î¼ Â± 3Ïƒ): **â‰ˆ 99,7%** das pessoas

---

### DistribuiÃ§Ã£o Normal PadrÃ£o (Z)

Quando a mÃ©dia Ã© 0 e o desvio padrÃ£o Ã© 1, temos a **Normal PadrÃ£o**: Z ~ N(0, 1).

Para usar tabelas estatÃ­sticas, transformamos qualquer Normal em Normal PadrÃ£o pela **padronizaÃ§Ã£o (escore Z)**:

```
Z = (X âˆ’ Î¼) / Ïƒ
```

**Lendo a fÃ³rmula:**
- **X** = valor que queremos avaliar
- **Î¼** = mÃ©dia da distribuiÃ§Ã£o
- **Ïƒ** = desvio padrÃ£o
- **Z** = quantos desvios padrÃ£o X estÃ¡ acima (Z>0) ou abaixo (Z<0) da mÃ©dia

---

**ğŸ“Œ Exemplo 1:**
Na distribuiÃ§Ã£o de alturas (Î¼=170, Ïƒ=10), qual o Z de uma pessoa com 185 cm?

```
Z = (185 âˆ’ 170) / 10 = 15/10 = 1,5
```
A pessoa estÃ¡ **1,5 desvios padrÃ£o acima** da mÃ©dia.

**ğŸ“Œ Exemplo 2:**
Na mesma distribuiÃ§Ã£o, qual o Z de uma pessoa com 155 cm?

```
Z = (155 âˆ’ 170) / 10 = âˆ’15/10 = âˆ’1,5
```
A pessoa estÃ¡ **1,5 desvios padrÃ£o abaixo** da mÃ©dia.

---

### Teorema Central do Limite (TCL)

Este Ã© um dos resultados mais poderosos de toda a estatÃ­stica:

> **Independente da distribuiÃ§Ã£o original da populaÃ§Ã£o**, a distribuiÃ§Ã£o das **mÃ©dias amostrais** se aproxima de uma **distribuiÃ§Ã£o normal** conforme o tamanho da amostra (n) aumenta.
>
> Na prÃ¡tica: para **n â‰¥ 30**, a distribuiÃ§Ã£o das mÃ©dias jÃ¡ Ã© aproximadamente normal.

**Por que isso importa?**
O TCL justifica o uso da distribuiÃ§Ã£o normal em testes de hipÃ³teses e intervalos de confianÃ§a, **mesmo quando a populaÃ§Ã£o nÃ£o Ã© normal**.

**ğŸ“Œ Exemplo:**
O tempo de atendimento em uma agÃªncia bancÃ¡ria tem distribuiÃ§Ã£o desconhecida (possivelmente assimÃ©trica). Se coletarmos 50 amostras de tamanho 30 e calcularmos a mÃ©dia de cada uma, a distribuiÃ§Ã£o dessas 50 mÃ©dias serÃ¡ **aproximadamente normal**, mesmo que os dados originais nÃ£o sejam!

> ğŸ† **Dica de concurso:** TCL Ã© questÃ£o clÃ¡ssica. A banca frequentemente afirma que "Ã© necessÃ¡rio que a populaÃ§Ã£o seja normal para aplicar testes estatÃ­sticos" â€” isso Ã© **FALSO** graÃ§as ao TCL com amostras grandes.

---

## âœ… Resumo â€” O que mais cai em concurso

| TÃ³pico | Ponto CrÃ­tico |
|--------|---------------|
| **Probabilidade bÃ¡sica** | P(A) = favorÃ¡veis/total; P(Aá¶œ) = 1 âˆ’ P(A) |
| **Probabilidade condicional** | P(A\|B) = P(Aâˆ©B) / P(B) |
| **IndependÃªncia** | P(Aâˆ©B) = P(A) Ã— P(B) â†’ independentes |
| **Teorema de Bayes** | P(A\|B) = P(B\|A)Ã—P(A) / P(B) |
| **Binomial** | Quando usar: n fixo, 2 resultados, independente, p constante |
| **MÃ©dia binomial** | Î¼ = n Ã— p |
| **Regra 68-95-99,7** | Percentuais da normal dentro de Â±1Ïƒ, Â±2Ïƒ, Â±3Ïƒ |
| **Escore Z** | Z = (X âˆ’ Î¼) / Ïƒ |
| **TCL** | MÃ©dias amostrais â†’ normal para n â‰¥ 30, mesmo se pop. nÃ£o for |
| **Normal padrÃ£o** | MÃ©dia = 0, Desvio padrÃ£o = 1 |

---

## ğŸ”— ConexÃ£o com o prÃ³ximo tÃ³pico (1.3 â€” InferÃªncia EstatÃ­stica)

A probabilidade nos deu as ferramentas para modelar a incerteza. A **InferÃªncia EstatÃ­stica** vai usar essas ferramentas para **tomar decisÃµes** com base em dados:

- A **distribuiÃ§Ã£o normal** e o **TCL** sÃ£o usados na construÃ§Ã£o de intervalos de confianÃ§a
- A **probabilidade condicional** Ã© o fundamento dos testes de hipÃ³teses (p-valor)
- O **Teorema de Bayes** reaparece na InferÃªncia Bayesiana e no Naive Bayes (MÃ³dulo 5)

---

*ğŸ“… PrÃ³ximo tÃ³pico: **1.3 â€” InferÃªncia EstatÃ­stica***
